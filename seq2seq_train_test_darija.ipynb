{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 45\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
    "       # p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 19679 sentence pairs\n",
      "Trimmed to 19679 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 6531\n",
      "dar 14863\n",
      "['the whole ball of wax', ' bb o tben']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('dar', 'eng', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs2 = random.sample(pairs,len(pairs))\n",
    "pairs_train = pairs2[:17000]\n",
    "pairs_test = pairs2[17000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    #showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PB\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 14s (- 447m 3s) (1000 0%) 5.3853\n",
      "4m 28s (- 443m 40s) (2000 1%) 5.1997\n",
      "6m 31s (- 428m 49s) (3000 1%) 5.1456\n",
      "8m 40s (- 425m 1s) (4000 2%) 5.2519\n",
      "10m 52s (- 423m 53s) (5000 2%) 5.1969\n",
      "13m 8s (- 424m 56s) (6000 3%) 5.2348\n",
      "15m 17s (- 421m 26s) (7000 3%) 5.2002\n",
      "17m 28s (- 419m 16s) (8000 4%) 5.1814\n",
      "19m 35s (- 415m 57s) (9000 4%) 5.1660\n",
      "21m 40s (- 411m 57s) (10000 5%) 5.1290\n",
      "23m 55s (- 410m 56s) (11000 5%) 5.1277\n",
      "26m 19s (- 412m 18s) (12000 6%) 5.0826\n",
      "28m 33s (- 410m 48s) (13000 6%) 5.0671\n",
      "30m 45s (- 408m 33s) (14000 7%) 5.0518\n",
      "32m 59s (- 406m 52s) (15000 7%) 5.0550\n",
      "35m 14s (- 405m 18s) (16000 8%) 5.0407\n",
      "37m 31s (- 404m 0s) (17000 8%) 5.0148\n",
      "39m 47s (- 402m 20s) (18000 9%) 5.0129\n",
      "42m 1s (- 400m 19s) (19000 9%) 4.9237\n",
      "44m 17s (- 398m 35s) (20000 10%) 4.9073\n",
      "46m 32s (- 396m 40s) (21000 10%) 4.9093\n",
      "48m 49s (- 395m 4s) (22000 11%) 4.9056\n",
      "51m 3s (- 392m 54s) (23000 11%) 4.8572\n",
      "53m 21s (- 391m 17s) (24000 12%) 4.8897\n",
      "55m 34s (- 388m 58s) (25000 12%) 4.7207\n",
      "57m 52s (- 387m 20s) (26000 13%) 4.7901\n",
      "60m 11s (- 385m 37s) (27000 13%) 4.7266\n",
      "62m 32s (- 384m 9s) (28000 14%) 4.7045\n",
      "64m 50s (- 382m 22s) (29000 14%) 4.6893\n",
      "67m 9s (- 380m 35s) (30000 15%) 4.6836\n",
      "69m 24s (- 378m 20s) (31000 15%) 4.7012\n",
      "71m 43s (- 376m 32s) (32000 16%) 4.5980\n",
      "74m 4s (- 374m 51s) (33000 16%) 4.6441\n",
      "76m 22s (- 372m 51s) (34000 17%) 4.5931\n",
      "78m 40s (- 370m 54s) (35000 17%) 4.6469\n",
      "80m 55s (- 368m 37s) (36000 18%) 4.5069\n",
      "83m 17s (- 366m 54s) (37000 18%) 4.5221\n",
      "85m 37s (- 365m 3s) (38000 19%) 4.5188\n",
      "88m 5s (- 363m 39s) (39000 19%) 4.4914\n",
      "90m 25s (- 361m 41s) (40000 20%) 4.4805\n",
      "92m 45s (- 359m 44s) (41000 20%) 4.3694\n",
      "95m 3s (- 357m 34s) (42000 21%) 4.3850\n",
      "97m 25s (- 355m 42s) (43000 21%) 4.3836\n",
      "99m 43s (- 353m 33s) (44000 22%) 4.2990\n",
      "102m 4s (- 351m 35s) (45000 22%) 4.3974\n",
      "104m 22s (- 349m 25s) (46000 23%) 4.3946\n",
      "106m 36s (- 347m 4s) (47000 23%) 4.2999\n",
      "108m 54s (- 344m 53s) (48000 24%) 4.2698\n",
      "111m 12s (- 342m 42s) (49000 24%) 4.2719\n",
      "113m 28s (- 340m 26s) (50000 25%) 4.2415\n",
      "115m 45s (- 338m 12s) (51000 25%) 4.1521\n",
      "118m 3s (- 335m 59s) (52000 26%) 4.1610\n",
      "120m 22s (- 333m 53s) (53000 26%) 4.0902\n",
      "122m 43s (- 331m 48s) (54000 27%) 4.1288\n",
      "125m 1s (- 329m 35s) (55000 27%) 4.0787\n",
      "127m 20s (- 327m 27s) (56000 28%) 4.0959\n",
      "129m 40s (- 325m 19s) (57000 28%) 4.0516\n",
      "131m 55s (- 322m 58s) (58000 28%) 4.0349\n",
      "134m 13s (- 320m 47s) (59000 29%) 4.0607\n",
      "136m 29s (- 318m 29s) (60000 30%) 3.9424\n",
      "138m 48s (- 316m 18s) (61000 30%) 3.9457\n",
      "141m 11s (- 314m 14s) (62000 31%) 3.9957\n",
      "143m 32s (- 312m 9s) (63000 31%) 3.9329\n",
      "145m 52s (- 309m 58s) (64000 32%) 3.9279\n",
      "148m 7s (- 307m 39s) (65000 32%) 3.8728\n",
      "150m 29s (- 305m 32s) (66000 33%) 3.8409\n",
      "153m 0s (- 303m 44s) (67000 33%) 3.7612\n",
      "155m 22s (- 301m 36s) (68000 34%) 3.8461\n",
      "157m 39s (- 299m 19s) (69000 34%) 3.7080\n",
      "160m 3s (- 297m 14s) (70000 35%) 3.8076\n",
      "162m 21s (- 294m 59s) (71000 35%) 3.6855\n",
      "164m 44s (- 292m 52s) (72000 36%) 3.6680\n",
      "167m 4s (- 290m 39s) (73000 36%) 3.6619\n",
      "169m 22s (- 288m 23s) (74000 37%) 3.6278\n",
      "171m 43s (- 286m 12s) (75000 37%) 3.5881\n",
      "174m 5s (- 284m 3s) (76000 38%) 3.5961\n",
      "176m 24s (- 281m 47s) (77000 38%) 3.6055\n",
      "178m 46s (- 279m 36s) (78000 39%) 3.5917\n",
      "181m 8s (- 277m 26s) (79000 39%) 3.6177\n",
      "183m 27s (- 275m 11s) (80000 40%) 3.5236\n",
      "185m 41s (- 272m 48s) (81000 40%) 3.4573\n",
      "188m 2s (- 270m 35s) (82000 41%) 3.5249\n",
      "190m 25s (- 268m 26s) (83000 41%) 3.4678\n",
      "192m 48s (- 266m 16s) (84000 42%) 3.3691\n",
      "195m 11s (- 264m 5s) (85000 42%) 3.4804\n",
      "197m 33s (- 261m 52s) (86000 43%) 3.4636\n",
      "199m 57s (- 259m 42s) (87000 43%) 3.3977\n",
      "202m 17s (- 257m 28s) (88000 44%) 3.3880\n",
      "204m 41s (- 255m 17s) (89000 44%) 3.3776\n",
      "206m 58s (- 252m 57s) (90000 45%) 3.3582\n",
      "209m 21s (- 250m 46s) (91000 45%) 3.3693\n",
      "211m 42s (- 248m 32s) (92000 46%) 3.2296\n",
      "214m 2s (- 246m 15s) (93000 46%) 3.2813\n",
      "216m 21s (- 243m 58s) (94000 47%) 3.3008\n",
      "218m 40s (- 241m 41s) (95000 47%) 3.2826\n",
      "220m 58s (- 239m 23s) (96000 48%) 3.2543\n",
      "223m 16s (- 237m 5s) (97000 48%) 3.2330\n",
      "225m 34s (- 234m 46s) (98000 49%) 3.0830\n",
      "227m 52s (- 232m 29s) (99000 49%) 3.1399\n",
      "230m 14s (- 230m 14s) (100000 50%) 3.1475\n",
      "232m 28s (- 227m 51s) (101000 50%) 3.0263\n",
      "234m 47s (- 225m 35s) (102000 51%) 3.0822\n",
      "237m 12s (- 223m 23s) (103000 51%) 3.0834\n",
      "239m 30s (- 221m 4s) (104000 52%) 3.1201\n",
      "241m 53s (- 218m 51s) (105000 52%) 3.0765\n",
      "244m 15s (- 216m 36s) (106000 53%) 2.9944\n",
      "246m 32s (- 214m 16s) (107000 53%) 3.0139\n",
      "248m 51s (- 211m 59s) (108000 54%) 3.0341\n",
      "251m 9s (- 209m 40s) (109000 54%) 2.9305\n",
      "253m 30s (- 207m 24s) (110000 55%) 2.9326\n",
      "255m 54s (- 205m 11s) (111000 55%) 2.9899\n",
      "258m 14s (- 202m 54s) (112000 56%) 2.8978\n",
      "260m 41s (- 200m 42s) (113000 56%) 2.9934\n",
      "263m 0s (- 198m 24s) (114000 56%) 2.9279\n",
      "265m 20s (- 196m 7s) (115000 57%) 2.8269\n",
      "267m 41s (- 193m 50s) (116000 57%) 2.9226\n",
      "270m 4s (- 191m 35s) (117000 58%) 2.8526\n",
      "272m 25s (- 189m 19s) (118000 59%) 2.8896\n",
      "274m 52s (- 187m 5s) (119000 59%) 2.8216\n",
      "277m 11s (- 184m 47s) (120000 60%) 2.7528\n",
      "279m 33s (- 182m 31s) (121000 60%) 2.6769\n",
      "281m 53s (- 180m 13s) (122000 61%) 2.7172\n",
      "284m 13s (- 177m 55s) (123000 61%) 2.6787\n",
      "286m 37s (- 175m 40s) (124000 62%) 2.7259\n",
      "289m 5s (- 173m 27s) (125000 62%) 2.7782\n",
      "291m 27s (- 171m 10s) (126000 63%) 2.6979\n",
      "293m 48s (- 168m 52s) (127000 63%) 2.6167\n",
      "296m 12s (- 166m 36s) (128000 64%) 2.6791\n",
      "298m 31s (- 164m 18s) (129000 64%) 2.5934\n",
      "300m 57s (- 162m 3s) (130000 65%) 2.6367\n",
      "303m 24s (- 159m 48s) (131000 65%) 2.6264\n",
      "305m 45s (- 157m 30s) (132000 66%) 2.5291\n",
      "308m 5s (- 155m 12s) (133000 66%) 2.4571\n",
      "310m 29s (- 152m 55s) (134000 67%) 2.5110\n",
      "312m 47s (- 150m 36s) (135000 67%) 2.5533\n",
      "315m 9s (- 148m 18s) (136000 68%) 2.5674\n",
      "317m 37s (- 146m 3s) (137000 68%) 2.4739\n",
      "320m 2s (- 143m 47s) (138000 69%) 2.4608\n",
      "322m 24s (- 141m 29s) (139000 69%) 2.4641\n",
      "324m 45s (- 139m 10s) (140000 70%) 2.4573\n",
      "327m 10s (- 136m 54s) (141000 70%) 2.3630\n",
      "329m 32s (- 134m 36s) (142000 71%) 2.3887\n",
      "331m 55s (- 132m 18s) (143000 71%) 2.4592\n",
      "334m 14s (- 129m 59s) (144000 72%) 2.3994\n",
      "336m 32s (- 127m 39s) (145000 72%) 2.3204\n",
      "338m 54s (- 125m 21s) (146000 73%) 2.3279\n",
      "341m 18s (- 123m 3s) (147000 73%) 2.3401\n",
      "343m 50s (- 120m 48s) (148000 74%) 2.3413\n",
      "346m 14s (- 118m 30s) (149000 74%) 2.3792\n",
      "348m 36s (- 116m 12s) (150000 75%) 2.2540\n",
      "350m 54s (- 113m 52s) (151000 75%) 2.2808\n",
      "353m 17s (- 111m 33s) (152000 76%) 2.2683\n",
      "355m 43s (- 109m 16s) (153000 76%) 2.2150\n",
      "358m 10s (- 106m 59s) (154000 77%) 2.3093\n",
      "360m 38s (- 104m 42s) (155000 77%) 2.2063\n",
      "363m 4s (- 102m 24s) (156000 78%) 2.2442\n",
      "365m 29s (- 100m 6s) (157000 78%) 2.1554\n",
      "367m 46s (- 97m 45s) (158000 79%) 2.2073\n",
      "370m 11s (- 95m 27s) (159000 79%) 2.1974\n",
      "372m 42s (- 93m 10s) (160000 80%) 2.2385\n",
      "375m 4s (- 90m 51s) (161000 80%) 2.1702\n",
      "377m 26s (- 88m 32s) (162000 81%) 2.2130\n",
      "379m 45s (- 86m 12s) (163000 81%) 2.1153\n",
      "382m 5s (- 83m 52s) (164000 82%) 2.1191\n",
      "384m 28s (- 81m 33s) (165000 82%) 2.1347\n",
      "386m 49s (- 79m 13s) (166000 83%) 2.0938\n",
      "389m 9s (- 76m 54s) (167000 83%) 2.1260\n",
      "391m 30s (- 74m 34s) (168000 84%) 2.0500\n",
      "393m 47s (- 72m 14s) (169000 84%) 2.0456\n",
      "396m 4s (- 69m 53s) (170000 85%) 1.9665\n",
      "398m 23s (- 67m 33s) (171000 85%) 1.9755\n",
      "400m 41s (- 65m 13s) (172000 86%) 1.9808\n",
      "403m 1s (- 62m 53s) (173000 86%) 1.9771\n",
      "405m 21s (- 60m 34s) (174000 87%) 1.9669\n",
      "407m 41s (- 58m 14s) (175000 87%) 1.9250\n",
      "410m 5s (- 55m 55s) (176000 88%) 1.9882\n",
      "412m 25s (- 53m 35s) (177000 88%) 1.8830\n",
      "414m 46s (- 51m 15s) (178000 89%) 1.8854\n",
      "417m 5s (- 48m 55s) (179000 89%) 1.9227\n",
      "419m 27s (- 46m 36s) (180000 90%) 1.9341\n",
      "421m 54s (- 44m 17s) (181000 90%) 1.9514\n",
      "424m 16s (- 41m 57s) (182000 91%) 1.8996\n",
      "426m 36s (- 39m 37s) (183000 91%) 1.9309\n",
      "429m 0s (- 37m 18s) (184000 92%) 1.8415\n",
      "431m 19s (- 34m 58s) (185000 92%) 1.8196\n",
      "433m 41s (- 32m 38s) (186000 93%) 1.8944\n",
      "436m 1s (- 30m 18s) (187000 93%) 1.7972\n",
      "438m 22s (- 27m 58s) (188000 94%) 1.8206\n",
      "440m 47s (- 25m 39s) (189000 94%) 1.8902\n",
      "443m 8s (- 23m 19s) (190000 95%) 1.8082\n",
      "445m 31s (- 20m 59s) (191000 95%) 1.8069\n",
      "447m 57s (- 18m 39s) (192000 96%) 1.7894\n",
      "450m 17s (- 16m 19s) (193000 96%) 1.8263\n",
      "452m 43s (- 14m 0s) (194000 97%) 1.8173\n",
      "455m 6s (- 11m 40s) (195000 97%) 1.7501\n",
      "457m 28s (- 9m 20s) (196000 98%) 1.7683\n",
      "459m 52s (- 7m 0s) (197000 98%) 1.7543\n",
      "462m 13s (- 4m 40s) (198000 99%) 1.7382\n",
      "464m 34s (- 2m 20s) (199000 99%) 1.7721\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 200000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = torch.load('encoder2.pt')\n",
    "attn_decoder1 = torch.load('attn_decoder2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 29s (- 196m 48s) (1000 1%) 2.6934\n",
      "5m 2s (- 196m 45s) (2000 2%) 2.7321\n",
      "7m 37s (- 195m 49s) (3000 3%) 2.7411\n",
      "10m 5s (- 191m 42s) (4000 5%) 2.6271\n",
      "12m 27s (- 186m 56s) (5000 6%) 2.6690\n",
      "14m 55s (- 184m 1s) (6000 7%) 2.5716\n",
      "17m 21s (- 180m 58s) (7000 8%) 2.6250\n",
      "19m 44s (- 177m 36s) (8000 10%) 2.5957\n",
      "22m 12s (- 175m 9s) (9000 11%) 2.6031\n",
      "24m 37s (- 172m 21s) (10000 12%) 2.6587\n",
      "32m 55s (- 206m 28s) (11000 13%) 2.5259\n",
      "35m 36s (- 201m 48s) (12000 15%) 2.5823\n",
      "38m 37s (- 199m 5s) (13000 16%) 2.4438\n",
      "41m 35s (- 196m 4s) (14000 17%) 2.5348\n",
      "44m 14s (- 191m 43s) (15000 18%) 2.5184\n",
      "46m 47s (- 187m 10s) (16000 20%) 2.5560\n",
      "49m 9s (- 182m 11s) (17000 21%) 2.4614\n",
      "51m 39s (- 177m 56s) (18000 22%) 2.4624\n",
      "54m 5s (- 173m 39s) (19000 23%) 2.3874\n",
      "58m 29s (- 175m 29s) (20000 25%) 2.4547\n",
      "60m 59s (- 171m 21s) (21000 26%) 2.3952\n",
      "63m 22s (- 167m 6s) (22000 27%) 2.3986\n",
      "66m 39s (- 165m 11s) (23000 28%) 2.4464\n",
      "69m 28s (- 162m 5s) (24000 30%) 2.3834\n",
      "72m 3s (- 158m 31s) (25000 31%) 2.3233\n",
      "74m 34s (- 154m 52s) (26000 32%) 2.2967\n",
      "77m 4s (- 151m 18s) (27000 33%) 2.3375\n",
      "79m 32s (- 147m 42s) (28000 35%) 2.2260\n",
      "82m 14s (- 144m 37s) (29000 36%) 2.4092\n",
      "84m 45s (- 141m 16s) (30000 37%) 2.2911\n",
      "87m 47s (- 138m 45s) (31000 38%) 2.2690\n",
      "90m 31s (- 135m 46s) (32000 40%) 2.3351\n",
      "93m 1s (- 132m 30s) (33000 41%) 2.2504\n",
      "95m 29s (- 129m 11s) (34000 42%) 2.2889\n",
      "97m 56s (- 125m 55s) (35000 43%) 2.1695\n",
      "100m 23s (- 122m 41s) (36000 45%) 2.2589\n",
      "102m 50s (- 119m 31s) (37000 46%) 2.2578\n",
      "105m 18s (- 116m 24s) (38000 47%) 2.1586\n",
      "107m 45s (- 113m 16s) (39000 48%) 2.1766\n",
      "110m 15s (- 110m 15s) (40000 50%) 2.1693\n",
      "112m 48s (- 107m 18s) (41000 51%) 2.1733\n",
      "115m 13s (- 104m 15s) (42000 52%) 2.1721\n",
      "117m 38s (- 101m 13s) (43000 53%) 2.0982\n",
      "120m 6s (- 98m 16s) (44000 55%) 2.1623\n",
      "122m 30s (- 95m 16s) (45000 56%) 2.1544\n",
      "124m 56s (- 92m 21s) (46000 57%) 2.0407\n",
      "127m 22s (- 89m 26s) (47000 58%) 2.0959\n",
      "129m 48s (- 86m 32s) (48000 60%) 2.0974\n",
      "132m 16s (- 83m 40s) (49000 61%) 1.9757\n",
      "134m 40s (- 80m 48s) (50000 62%) 2.0362\n",
      "137m 11s (- 78m 0s) (51000 63%) 2.0145\n",
      "139m 37s (- 75m 11s) (52000 65%) 2.0070\n",
      "142m 12s (- 72m 26s) (53000 66%) 1.9779\n",
      "144m 44s (- 69m 41s) (54000 67%) 1.9447\n",
      "147m 20s (- 66m 58s) (55000 68%) 1.9711\n",
      "149m 39s (- 64m 8s) (56000 70%) 1.8947\n",
      "152m 4s (- 61m 21s) (57000 71%) 1.9199\n",
      "154m 31s (- 58m 36s) (58000 72%) 1.9386\n",
      "157m 2s (- 55m 53s) (59000 73%) 1.9828\n",
      "159m 26s (- 53m 8s) (60000 75%) 1.8368\n",
      "161m 53s (- 50m 25s) (61000 76%) 1.8491\n",
      "164m 15s (- 47m 41s) (62000 77%) 1.8977\n",
      "166m 44s (- 44m 59s) (63000 78%) 1.9119\n",
      "169m 27s (- 42m 21s) (64000 80%) 1.8737\n",
      "172m 44s (- 39m 51s) (65000 81%) 1.8530\n",
      "175m 17s (- 37m 10s) (66000 82%) 1.9218\n",
      "177m 43s (- 34m 29s) (67000 83%) 1.8234\n",
      "180m 9s (- 31m 47s) (68000 85%) 1.8356\n",
      "182m 38s (- 29m 6s) (69000 86%) 1.8828\n",
      "184m 59s (- 26m 25s) (70000 87%) 1.8399\n",
      "187m 25s (- 23m 45s) (71000 88%) 1.8101\n",
      "189m 50s (- 21m 5s) (72000 90%) 1.7006\n",
      "192m 18s (- 18m 26s) (73000 91%) 1.7794\n",
      "194m 42s (- 15m 47s) (74000 92%) 1.7001\n",
      "197m 5s (- 13m 8s) (75000 93%) 1.6768\n",
      "199m 26s (- 10m 29s) (76000 95%) 1.6919\n",
      "201m 54s (- 7m 52s) (77000 96%) 1.7231\n",
      "204m 24s (- 5m 14s) (78000 97%) 1.7191\n",
      "206m 50s (- 2m 37s) (79000 98%) 1.7171\n",
      "209m 20s (- 0m 0s) (80000 100%) 1.7106\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, attn_decoder1, 80000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurclaude/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/arthurclaude/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(encoder1, 'encoder21.pt')\n",
    "torch.save(attn_decoder1, 'attn_decoder21.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 31s (- 123m 23s) (1000 2%) 1.6679\n",
      "5m 0s (- 120m 2s) (2000 4%) 1.6817\n",
      "7m 31s (- 118m 0s) (3000 6%) 1.6963\n",
      "9m 57s (- 114m 26s) (4000 8%) 1.6856\n",
      "12m 26s (- 111m 57s) (5000 10%) 1.7041\n",
      "14m 52s (- 109m 4s) (6000 12%) 1.7659\n",
      "17m 18s (- 106m 22s) (7000 14%) 1.6975\n",
      "19m 56s (- 104m 43s) (8000 16%) 1.6195\n",
      "22m 24s (- 102m 6s) (9000 18%) 1.6508\n",
      "24m 48s (- 99m 15s) (10000 20%) 1.6690\n",
      "27m 12s (- 96m 28s) (11000 22%) 1.6611\n",
      "29m 37s (- 93m 49s) (12000 24%) 1.5446\n",
      "32m 5s (- 91m 19s) (13000 26%) 1.6312\n",
      "34m 24s (- 88m 29s) (14000 28%) 1.5630\n",
      "36m 54s (- 86m 6s) (15000 30%) 1.6733\n",
      "39m 19s (- 83m 32s) (16000 32%) 1.6098\n",
      "41m 46s (- 81m 5s) (17000 34%) 1.6120\n",
      "44m 17s (- 78m 43s) (18000 36%) 1.6116\n",
      "46m 48s (- 76m 22s) (19000 38%) 1.6085\n",
      "49m 21s (- 74m 2s) (20000 40%) 1.6054\n",
      "51m 45s (- 71m 28s) (21000 42%) 1.5401\n",
      "54m 17s (- 69m 6s) (22000 44%) 1.5537\n",
      "56m 49s (- 66m 42s) (23000 46%) 1.5539\n",
      "59m 18s (- 64m 14s) (24000 48%) 1.5261\n",
      "61m 39s (- 61m 39s) (25000 50%) 1.5051\n",
      "64m 4s (- 59m 8s) (26000 52%) 1.5190\n",
      "66m 29s (- 56m 38s) (27000 54%) 1.5237\n",
      "68m 54s (- 54m 8s) (28000 56%) 1.4902\n",
      "71m 22s (- 51m 41s) (29000 57%) 1.5080\n",
      "73m 52s (- 49m 15s) (30000 60%) 1.5344\n",
      "76m 20s (- 46m 47s) (31000 62%) 1.5162\n",
      "78m 43s (- 44m 16s) (32000 64%) 1.4515\n",
      "81m 13s (- 41m 50s) (33000 66%) 1.4916\n",
      "83m 38s (- 39m 21s) (34000 68%) 1.4772\n",
      "86m 5s (- 36m 53s) (35000 70%) 1.4834\n",
      "88m 40s (- 34m 29s) (36000 72%) 1.4866\n",
      "91m 7s (- 32m 1s) (37000 74%) 1.4263\n",
      "93m 36s (- 29m 33s) (38000 76%) 1.4546\n",
      "96m 5s (- 27m 6s) (39000 78%) 1.4426\n",
      "98m 30s (- 24m 37s) (40000 80%) 1.4529\n",
      "100m 57s (- 22m 9s) (41000 82%) 1.4940\n",
      "103m 26s (- 19m 42s) (42000 84%) 1.3880\n",
      "105m 53s (- 17m 14s) (43000 86%) 1.4643\n",
      "108m 17s (- 14m 46s) (44000 88%) 1.4458\n",
      "110m 48s (- 12m 18s) (45000 90%) 1.4262\n",
      "113m 14s (- 9m 50s) (46000 92%) 1.3949\n",
      "115m 42s (- 7m 23s) (47000 94%) 1.4345\n",
      "118m 8s (- 4m 55s) (48000 96%) 1.4185\n",
      "120m 34s (- 2m 27s) (49000 98%) 1.3738\n",
      "123m 7s (- 0m 0s) (50000 100%) 1.4355\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, attn_decoder1, 50000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1, 'encoder21.pt')\n",
    "torch.save(attn_decoder1, 'attn_decoder21.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 42s (- 132m 51s) (1000 2%) 1.4227\n",
      "5m 18s (- 127m 19s) (2000 4%) 1.3950\n",
      "7m 49s (- 122m 40s) (3000 6%) 1.3568\n",
      "10m 20s (- 118m 51s) (4000 8%) 1.3838\n",
      "12m 51s (- 115m 45s) (5000 10%) 1.4212\n",
      "15m 27s (- 113m 22s) (6000 12%) 1.4659\n",
      "18m 2s (- 110m 49s) (7000 14%) 1.3848\n",
      "20m 32s (- 107m 48s) (8000 16%) 1.3956\n",
      "22m 55s (- 104m 27s) (9000 18%) 1.3533\n",
      "25m 23s (- 101m 34s) (10000 20%) 1.3647\n",
      "27m 51s (- 98m 46s) (11000 22%) 1.3361\n",
      "30m 16s (- 95m 53s) (12000 24%) 1.3888\n",
      "32m 41s (- 93m 2s) (13000 26%) 1.3008\n",
      "35m 10s (- 90m 28s) (14000 28%) 1.3782\n",
      "37m 37s (- 87m 47s) (15000 30%) 1.3178\n",
      "40m 3s (- 85m 8s) (16000 32%) 1.3619\n",
      "42m 29s (- 82m 28s) (17000 34%) 1.3300\n",
      "44m 55s (- 79m 51s) (18000 36%) 1.3730\n",
      "47m 20s (- 77m 14s) (19000 38%) 1.2917\n",
      "49m 47s (- 74m 41s) (20000 40%) 1.3221\n",
      "52m 13s (- 72m 7s) (21000 42%) 1.3652\n",
      "54m 42s (- 69m 37s) (22000 44%) 1.3465\n",
      "57m 13s (- 67m 10s) (23000 46%) 1.3066\n",
      "59m 39s (- 64m 37s) (24000 48%) 1.2848\n",
      "62m 5s (- 62m 5s) (25000 50%) 1.3443\n",
      "64m 31s (- 59m 33s) (26000 52%) 1.3556\n",
      "66m 58s (- 57m 2s) (27000 54%) 1.3527\n",
      "69m 20s (- 54m 29s) (28000 56%) 1.3146\n",
      "71m 53s (- 52m 3s) (29000 57%) 1.4331\n",
      "74m 23s (- 49m 35s) (30000 60%) 1.3081\n",
      "76m 53s (- 47m 7s) (31000 62%) 1.3288\n",
      "79m 21s (- 44m 38s) (32000 64%) 1.3020\n",
      "81m 51s (- 42m 10s) (33000 66%) 1.3422\n",
      "84m 13s (- 39m 37s) (34000 68%) 1.2677\n",
      "86m 38s (- 37m 7s) (35000 70%) 1.3121\n",
      "89m 4s (- 34m 38s) (36000 72%) 1.3567\n",
      "91m 36s (- 32m 11s) (37000 74%) 1.3055\n",
      "94m 7s (- 29m 43s) (38000 76%) 1.3603\n",
      "96m 36s (- 27m 14s) (39000 78%) 1.2479\n",
      "98m 56s (- 24m 44s) (40000 80%) 1.2388\n",
      "101m 24s (- 22m 15s) (41000 82%) 1.2862\n",
      "103m 48s (- 19m 46s) (42000 84%) 1.2802\n",
      "106m 15s (- 17m 17s) (43000 86%) 1.2528\n",
      "108m 42s (- 14m 49s) (44000 88%) 1.3190\n",
      "111m 8s (- 12m 20s) (45000 90%) 1.2496\n",
      "113m 35s (- 9m 52s) (46000 92%) 1.2742\n",
      "116m 5s (- 7m 24s) (47000 94%) 1.2900\n",
      "118m 37s (- 4m 56s) (48000 96%) 1.2905\n",
      "121m 6s (- 2m 28s) (49000 98%) 1.2346\n",
      "123m 37s (- 0m 0s) (50000 100%) 1.2847\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, attn_decoder1, 50000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total: 300k iterations\n",
    "torch.save(encoder1, 'encoder21.pt')\n",
    "torch.save(attn_decoder1, 'attn_decoder21.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = torch.load('encoder21.pt')\n",
    "dec = torch.load('attn_decoder21.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(enc, dec, \"\")[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
