{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset-main/sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_cat_files = [f for f in listdir('dataset-main/semantic categories') if isfile(join('dataset-main/semantic categories', f))]\n",
    "sem_cat_files.remove('femalenames.csv')\n",
    "sem_cat_files.remove('malenames.csv')\n",
    "sem_cat_files = ['semantic categories/' + x for x in sem_cat_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_cat_files = ['adjectives.csv', 'adverbs.csv', 'nouns.csv', 'prepositions.csv', 'pronouns.csv', 'verbs.csv']\n",
    "synt_cat_files = ['syntactic categories/' + x for x in synt_cat_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra_files = ['idioms.csv', 'proverbs.csv', 'utils.csv', 'weird.csv']\n",
    "xtra_files = ['x-tra/' + x for x in xtra_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sem_cat_files + synt_cat_files + xtra_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semantic categories/art.csv\n",
      "semantic categories/education.csv\n",
      "semantic categories/emotions.csv\n",
      "semantic categories/environment.csv\n",
      "semantic categories/economy.csv\n",
      "semantic categories/religion.csv\n",
      "semantic categories/professions.csv\n",
      "semantic categories/plants.csv\n",
      "semantic categories/food.csv\n",
      "semantic categories/places.csv\n",
      "semantic categories/family.csv\n",
      "semantic categories/sport.csv\n",
      "semantic categories/humanbody.csv\n",
      "semantic categories/numbers.csv\n",
      "semantic categories/colors.csv\n",
      "semantic categories/clothes.csv\n",
      "semantic categories/health.csv\n",
      "semantic categories/animals.csv\n",
      "semantic categories/time.csv\n",
      "syntactic categories/adjectives.csv\n",
      "syntactic categories/adverbs.csv\n",
      "syntactic categories/nouns.csv\n",
      "syntactic categories/prepositions.csv\n",
      "syntactic categories/pronouns.csv\n",
      "syntactic categories/verbs.csv\n",
      "x-tra/idioms.csv\n",
      "x-tra/proverbs.csv\n",
      "x-tra/utils.csv\n",
      "x-tra/weird.csv\n"
     ]
    }
   ],
   "source": [
    "data = {'english': [],\n",
    "        'darija': []}\n",
    "for name in files:\n",
    "    print(name)\n",
    "    if name != 'x-tra/idioms.csv' and name != 'x-tra/proverbs.csv':\n",
    "        df_int = pd.read_csv('dataset-main/' + name)\n",
    "        for x in range(1,7):\n",
    "            col = 'n' + str(x)\n",
    "            if col in df_int.columns:\n",
    "                for i in range(df_int.shape[0]):\n",
    "                    data['english'].append(df_int.loc[i]['eng'])\n",
    "                    col = 'n' + str(x)\n",
    "                    data['darija'].append(df_int.loc[i][col])\n",
    "    else:\n",
    "        df_int = pd.read_csv('dataset-main/' + name)\n",
    "        for i in range(df_int.shape[0]):\n",
    "                data['english'].append(df_int.loc[i]['eng'])\n",
    "                data['darija'].append(df_int.loc[i]['darija'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data)\n",
    "df2 = df2.dropna(0)\n",
    "df2 = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df, df2], axis=0).reset_index()\n",
    "df_total = df_total.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dar-eng.txt', 'w') as f:\n",
    "    for i in range(df_total.shape[0]):\n",
    "        f.write(df_total.loc[i]['darija']+'\\t'+df_total.loc[i]['english']+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
